# Detection Generalization Benchmark

A comprehensive benchmark framework for evaluating generalization performance of various backbone-detector combinations in object detection.

## ğŸ¯ Overview

**Detection Generalization Benchmark** is a research framework designed to systematically evaluate the generalization capabilities of different backbone and detector combinations in object detection tasks. This project is based on the hypothesis that **"heterogeneous combinations between backbones and detectors may cause generalization performance degradation"**.

## ğŸ”¬ Research Background

Object detection models consist of two main components: **backbone** and **detector**, which have different learning objectives, data distributions, and processing methods:

### Detector Characteristics by Type:
- **1-stage detectors** (e.g., YOLO, RetinaNet)
- **2-stage detectors** (e.g., Faster R-CNN, Cascade R-CNN)
- **End-to-end detectors** (e.g., DETR, DiffDet)

### Backbone Characteristics:
- **CNN-based** (ResNet, ConvNeXt, InternImage)
- **Transformer-based** (ViT, Swin, CLIP)

This research experimentally validates the hypothesis that when these differences are combined, especially in combinations where characteristics conflict, generalization performance may unexpectedly decrease.

## âœ¨ Key Features

### 1. Diverse Model Combinations
- **CNN Backbones**: ResNet, ConvNeXt, InternImage
- **Transformer Backbones**: ViT, Swin, CLIP
- **1-stage Detectors**: FocusNet, RetinaNet
- **2-stage Detectors**: Faster R-CNN, Cascade R-CNN
- **End-to-end Detectors**: DETR, DiffDet

### 2. Robustness Evaluation
Evaluates performance not only on clean COCO data but also on realistic environmental variations:
- Fog, low lighting conditions
- Noise, resolution degradation
- Other realistic image corruptions

### 3. Flexible Training Strategies
- **Full fine-tuning (ft)**: Train entire model
- **Parameter-efficient tuning (peft)**: Adapter-based training
- **Layer-wise tuning**: Train specific layers only
- **Decoder probing**: Train decoder only

## ğŸ› ï¸ Installation

### Requirements
- Python â‰¥ 3.9
- PyTorch â‰¥ 2.1
- CUDA-compatible GPU (recommended)
- OpenCV (optional, for demo and visualization)

### Setup Instructions

git clone https://github.com/012shin/detection-generalization-benchmark.git
cd detection-generalization-benchmark



2. **Install Detectron2**
For Linux (pre-compiled version)
python -m pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu113/torch1.10/index.html

Or build from source
cd detectron2
python -m pip install -e .

text

3. **Install project dependencies**
cd projects
python setup.py install


## ğŸš€ Usage

### 1. Training

Basic training command:
cd projects
python tools/train_net.py --config-file configs/[detector]/[backbone]/config.yaml --num-gpus 8

text

Examples:
Train Faster R-CNN + ResNet combination
python tools/train_net.py --config-file configs/faster-rcnn/resnet/faster_rcnn_R_50_FPN_1x.yaml --num-gpus 8

Train DETR + ViT combination
python tools/train_net.py --config-file configs/detr/vit/detr_vit_base.yaml --num-gpus 8

text

### 2. Evaluation

Evaluate trained models:
python tools/corruption_test.py --config-file configs/[detector]/[backbone]/config.yaml --eval-only MODEL.WEIGHTS path/to/model.pth

text

### 3. Robustness Testing

Evaluate robustness against image corruptions:
python tools/corruption_test.py --config-file configs/[detector]/[backbone]/config.yaml MODEL.WEIGHTS path/to/model.pkl



## ğŸ“„ License

This project is distributed under the Apache 2.0 License. See `LICENSE` file for details.

## ğŸ“š Citation

If you use this benchmark in your research, please cite:

@misc{detection-generalization-benchmark,
title={Detection Generalization Benchmark},
author={Korea University},
year={2024},
url={https://github.com/012shin/detection-generalization-benchmark}
}


## ğŸ“ Contact

For questions or bug reports about this project, please submit through GitHub Issues.

---

## ğŸ—ï¸ Project Structure

detection-generalization-benchmark/
â”œâ”€â”€ configs/ # Configuration files
â”‚ â”œâ”€â”€ base/
â”‚ â”œâ”€â”€ faster-rcnn/
â”‚ â”œâ”€â”€ retinanet/
â”‚ â””â”€â”€ ...
â”œâ”€â”€ projects/ # Main project code
â”‚ â”œâ”€â”€ tools/
â”‚ â”‚ â”œâ”€â”€ train_net.py
â”‚ â”‚ â””â”€â”€ corruption_test.py
â”‚ â””â”€â”€ setup.py
â”œâ”€â”€ detectron2/ # Detectron2 framework
â”œâ”€â”€ README.md
â””â”€â”€ LICENSE

## ğŸ” Evaluation Metrics

- **mAP (mean Average Precision)**: Standard object detection metric
- **Robustness Score**: Performance under various corruptions
- **Generalization Gap**: Difference between clean and corrupted performance
